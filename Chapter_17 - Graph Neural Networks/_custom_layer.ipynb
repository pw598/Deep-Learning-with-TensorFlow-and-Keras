{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d62489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dgl in /home/ana007652/.local/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from dgl) (4.62.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from dgl) (2.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from dgl) (2.25.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from dgl) (1.5.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/ana007652/.local/lib/python3.6/site-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from dgl) (1.19.5)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/envs/beakerx/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
      "Downloading /home/ana007652/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
      "Extracting file to /home/ana007652/.dgl/cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert value torch.float32 to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4fed11fe2a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mloss_fcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\"\"\"## More customization\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4fed11fe2a25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g, model, optimizer, loss_fcn, num_epochs, use_edge_weights)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_edge_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4fed11fe2a25>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, in_feat)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_save_spec\u001b[0;34m(self, inputs, args, kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m       \u001b[0mflat_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m       \u001b[0mflat_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Stop recording positional args once a non-tensor has been found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m       \u001b[0mflat_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m       \u001b[0mflat_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Stop recording positional args once a non-tensor has been found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mget_tensor_spec\u001b[0;34m(t, dynamic_batch, name)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Allow non-Tensors to pass through.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   raise TypeError(\"Cannot convert value %r to a TensorFlow DType.\" %\n\u001b[0;32m--> 722\u001b[0;31m                   (type_value,))\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert value torch.float32 to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"packt-18-custom-layer.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1bD35UW02Quufx4n-eBN1RZzrM_Fyfx1_\n",
    "\n",
    "# Custom GNN Layer\n",
    "\n",
    "Tensorflow and DGL re-implementation of PyTorch and DGL example at [Write your own GNN module](https://docs.dgl.ai/tutorials/blitz/3_message_passing.html#sphx-glr-tutorials-blitz-3-message-passing-py).\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# %env DGLBACKEND=tensorflow\n",
    "\n",
    "!pip install dgl\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "import dgl.function as fn\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"## Message passing and GNNs\"\"\"\n",
    "\n",
    "class CustomGraphSAGE(tf.keras.layers.Layer):\n",
    "  \"\"\"Graph convolution module used by the GraphSAGE model.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  in_feat : int\n",
    "      Input feature size.\n",
    "  out_feat : int\n",
    "      Output feature size.\n",
    "  \"\"\"\n",
    "  def __init__(self, in_feat, out_feat):\n",
    "    super(CustomGraphSAGE, self).__init__()\n",
    "    # A linear submodule for projecting the input and neighbor feature to the output.\n",
    "    self.linear = tf.keras.layers.Dense(out_feat, activation=tf.nn.relu)\n",
    "\n",
    "  def call(self, g, h):\n",
    "      \"\"\"Forward computation\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      g : Graph\n",
    "          The input graph.\n",
    "      h : Tensor\n",
    "          The input node feature.\n",
    "      \"\"\"\n",
    "      with g.local_scope():\n",
    "        g.ndata[\"h\"] = h\n",
    "        # update_all is a message passing API.\n",
    "        g.update_all(message_func=fn.copy_u('h', 'm'),\n",
    "                     reduce_func=fn.mean('m', 'h_N'))\n",
    "        h_N = g.ndata['h_N']\n",
    "        h_total = tf.concat([h, h_N], axis=1)\n",
    "        return self.linear(h_total)\n",
    "\n",
    "class CustomGNN(tf.keras.Model):\n",
    "  def __init__(self, g, in_feats, h_feats, num_classes):\n",
    "    super(CustomGNN, self).__init__()\n",
    "    self.g = g\n",
    "    self.conv1 = CustomGraphSAGE(in_feats, h_feats)\n",
    "    self.relu1 = tf.keras.layers.Activation(tf.nn.relu)\n",
    "    self.conv2 = CustomGraphSAGE(h_feats, num_classes)\n",
    "\n",
    "  def call(self, in_feat):\n",
    "    h = self.conv1(self.g, in_feat)\n",
    "    h = self.relu1(h)\n",
    "    h = self.conv2(self.g, h)\n",
    "    return h\n",
    "\n",
    "\"\"\"## Training Loop\"\"\"\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "g\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "def evaluate(model, features, labels, mask, edge_weights=None):\n",
    "  if edge_weights is None:\n",
    "    logits = model(features, training=False)\n",
    "  else:\n",
    "    logits = model(features, edge_weights, training=False)\n",
    "  logits = logits[mask]\n",
    "  labels = labels[mask]\n",
    "  indices = tf.math.argmax(logits, axis=1)\n",
    "  acc = tf.reduce_mean(tf.cast(indices == labels, dtype=tf.float32))\n",
    "  return acc.numpy().item()\n",
    "\n",
    "\n",
    "def train(g, model, optimizer, loss_fcn, num_epochs, use_edge_weights=False):\n",
    "  features = g.ndata[\"feat\"]\n",
    "  labels = g.ndata[\"label\"]\n",
    "  if use_edge_weights:\n",
    "    edge_weights = g.edata[\"w\"]\n",
    "\n",
    "  train_mask = g.ndata[\"train_mask\"]\n",
    "  val_mask = g.ndata[\"val_mask\"]\n",
    "  test_mask = g.ndata[\"test_mask\"]\n",
    "  for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "      if not use_edge_weights:\n",
    "        logits = model(features)\n",
    "      else:\n",
    "        logits = model(features, edge_weights)\n",
    "\n",
    "      loss_value = loss_fcn(labels[train_mask], logits[train_mask])\n",
    "      grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    if not use_edge_weights:\n",
    "      acc = evaluate(model, features, labels, val_mask)\n",
    "    else:\n",
    "      acc = evaluate(model, features, labels, val_mask, edge_weights=edge_weights)\n",
    "    if epoch % 10 == 0:\n",
    "      print(\"Epoch {:5d} | loss: {:.3f} | val_acc: {:.3f}\".format(\n",
    "          epoch, loss_value.numpy().item(), acc))\n",
    "\n",
    "  if not use_edge_weights:\n",
    "    acc = evaluate(model, features, labels, test_mask)\n",
    "  else:\n",
    "    acc = evaluate(model, features, labels, test_mask, edge_weights=edge_weights)\n",
    "  print(\"Test accuracy: {:.3f}\".format(acc))\n",
    "\n",
    "model = CustomGNN(g, g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train(g, model, optimizer, loss_fcn, NUM_EPOCHS)\n",
    "\n",
    "\"\"\"## More customization\"\"\"\n",
    "\n",
    "class CustomWeightedGraphSAGE(tf.keras.layers.Layer):\n",
    "  \"\"\"Graph convolution module used by the GraphSAGE model with edge weights.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  in_feat : int\n",
    "      Input feature size.\n",
    "  out_feat : int\n",
    "      Output feature size.\n",
    "  \"\"\"\n",
    "  def __init__(self, in_feat, out_feat):\n",
    "    super(CustomWeightedGraphSAGE, self).__init__()\n",
    "    # A linear submodule for projecting the input and neighbor feature to the output.\n",
    "    self.linear = tf.keras.layers.Dense(out_feat, activation=tf.nn.relu)\n",
    "\n",
    "  def call(self, g, h, w):\n",
    "    \"\"\"Forward computation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : Graph\n",
    "        The input graph.\n",
    "    h : Tensor\n",
    "        The input node feature.\n",
    "    w : Tensor\n",
    "        The edge weight.\n",
    "    \"\"\"\n",
    "    with g.local_scope():\n",
    "      g.ndata['h'] = h\n",
    "      g.edata['w'] = w\n",
    "      g.update_all(message_func=fn.u_mul_e('h', 'w', 'm'),\n",
    "                   reduce_func=fn.mean('m', 'h_N'))\n",
    "      h_N = g.ndata['h_N']\n",
    "      h_total = tf.concat([h, h_N], axis=1)\n",
    "      return self.linear(h_total)\n",
    "\n",
    "class CustomWeightedGNN(tf.keras.Model):\n",
    "  def __init__(self, g, in_feats, h_feats, num_classes):\n",
    "    super(CustomWeightedGNN, self).__init__()\n",
    "    self.g = g\n",
    "    self.conv1 = CustomWeightedGraphSAGE(in_feats, h_feats)\n",
    "    self.relu1 = tf.keras.layers.Activation(tf.nn.relu)\n",
    "    self.conv2 = CustomWeightedGraphSAGE(h_feats, num_classes)\n",
    "\n",
    "  def call(self, in_feat, edge_weights):\n",
    "    h = self.conv1(self.g, in_feat, edge_weights)\n",
    "    h = self.relu1(h)\n",
    "    h = self.conv2(self.g, h, edge_weights)\n",
    "    return h\n",
    "\n",
    "g.edata[\"w\"] = tf.cast(\n",
    "    tf.random.uniform((g.num_edges(), 1), minval=3, maxval=10, dtype=tf.int32),\n",
    "    dtype=tf.float32)\n",
    "g.edata[\"w\"]\n",
    "\n",
    "model = CustomWeightedGNN(g, g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train(g, model, optimizer, loss_fcn, NUM_EPOCHS, use_edge_weights=True)\n",
    "\n",
    "\"\"\"## Even more customization by User Defined Function\n",
    "\n",
    "Not tensorflow related, but useful to mention.\n",
    "\"\"\"\n",
    "\n",
    "def u_mul_e_udf(edges):\n",
    "  return {'m' : edges.src['h'] * edges.data['w']}\n",
    "\n",
    "def mean_udf(nodes):\n",
    "  return {'h_N': nodes.mailbox['m'].mean(1)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3b8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
